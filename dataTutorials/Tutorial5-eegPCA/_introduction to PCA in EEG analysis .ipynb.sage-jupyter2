{"exec_count":1,"start":1520381595914,"input":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline","state":"done","pos":2,"cell_type":"code","type":"cell","end":1520381598686,"id":"6dc673","kernel":"python3"}
{"exec_count":10,"start":1519249092500,"input":"from sklearn.preprocessing import StandardScaler","state":"done","pos":8,"cell_type":"code","type":"cell","end":1519249092607,"id":"3bc78c","kernel":"python3"}
{"exec_count":11,"start":1519249092617,"input":"scaler = StandardScaler()\nscaler.fit(df) #ajustamos el escalador a nuestro DataFrame utilizando fit()\nscaled_data = scaler.transform(df) #aplica el cambio de escala utilizando transform()","state":"done","pos":9,"cell_type":"code","type":"cell","end":1519249092629,"id":"13e13b","kernel":"python3"}
{"exec_count":12,"start":1519249092642,"input":"from sklearn.decomposition import PCA\npca_21comp = PCA(n_components=21) #especificamos el número de componentes principales.","state":"done","pos":11,"cell_type":"code","type":"cell","end":1519249092953,"id":"fbc022","kernel":"python3"}
{"exec_count":14,"start":1519249093025,"input":"data_pca21 = pca_21comp.transform(scaled_data) #aplica PCA","state":"done","pos":13,"cell_type":"code","type":"cell","end":1519249093030,"id":"20853d","kernel":"python3"}
{"exec_count":15,"start":1519249093035,"input":"percent =(pca_21comp.explained_variance_ratio_) # nos indica el porcentaje de varianza \n                                                # correspondiente a cada una de las componentes","state":"done","pos":15,"cell_type":"code","type":"cell","end":1519249093052,"id":"73cdfa","kernel":"python3"}
{"exec_count":7,"start":1519249070897,"input":"f = \"./eeg_test\"\n\nwith open(f, \"r\") as ins:\n    headerdata = []\n    \n    for line in ins:\n        headerdata.append((line.split(\"\\t\")))","state":"done","pos":4,"cell_type":"code","type":"cell","end":1519249070908,"id":"05acc4","kernel":"python3"}
{"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C3-A1</th>\n      <th>C4-A1</th>\n      <th>Cz-A1</th>\n      <th>F3-A1</th>\n      <th>F4-A1</th>\n      <th>F7-A1</th>\n      <th>F8-A1</th>\n      <th>Fz-A1</th>\n      <th>FP1-A1</th>\n      <th>FP2-A1</th>\n      <th>...</th>\n      <th>O1-A1</th>\n      <th>O2-A1</th>\n      <th>P3-A1</th>\n      <th>P4-A1</th>\n      <th>Pz-A1</th>\n      <th>T3-A1</th>\n      <th>T4-A1</th>\n      <th>T5-A1</th>\n      <th>T6-A1</th>\n      <th>A2-A1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-678.15448</td>\n      <td>-272.48465</td>\n      <td>-269.294586</td>\n      <td>-347.451172</td>\n      <td>-316.082184</td>\n      <td>-246.964142</td>\n      <td>-89.853477</td>\n      <td>-317.943054</td>\n      <td>-246.964142</td>\n      <td>-429.861145</td>\n      <td>...</td>\n      <td>-400.353058</td>\n      <td>-459.635101</td>\n      <td>-292.422546</td>\n      <td>-264.77533</td>\n      <td>-280.19397</td>\n      <td>-190.3405</td>\n      <td>-140.628662</td>\n      <td>-298.270996</td>\n      <td>-326.184082</td>\n      <td>373.237518\\n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-822.770752</td>\n      <td>-415.771698</td>\n      <td>-412.049957</td>\n      <td>-491.004059</td>\n      <td>-457.508392</td>\n      <td>-389.985352</td>\n      <td>-229.95047</td>\n      <td>-458.04007</td>\n      <td>-390.782867</td>\n      <td>-568.628967</td>\n      <td>...</td>\n      <td>-544.969299</td>\n      <td>-602.390442</td>\n      <td>-435.177917</td>\n      <td>-406.201508</td>\n      <td>-425.07605</td>\n      <td>-334.956757</td>\n      <td>-283.91571</td>\n      <td>-441.292206</td>\n      <td>-468.673615</td>\n      <td>232.874695\\n</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-866.899963</td>\n      <td>-460.432617</td>\n      <td>-460.432617</td>\n      <td>-541.513428</td>\n      <td>-496.58667</td>\n      <td>-435.443756</td>\n      <td>-277.003906</td>\n      <td>-503.232635</td>\n      <td>-439.697174</td>\n      <td>-617.011597</td>\n      <td>...</td>\n      <td>-591.756897</td>\n      <td>-649.178101</td>\n      <td>-482.497223</td>\n      <td>-455.913361</td>\n      <td>-474.787903</td>\n      <td>-381.478516</td>\n      <td>-329.905823</td>\n      <td>-492.599091</td>\n      <td>-516.524597</td>\n      <td>192.467209\\n</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-808.681274</td>\n      <td>-400.618896</td>\n      <td>-402.479767</td>\n      <td>-484.092255</td>\n      <td>-441.292206</td>\n      <td>-376.69342</td>\n      <td>-220.646103</td>\n      <td>-445.013947</td>\n      <td>-383.871063</td>\n      <td>-555.602844</td>\n      <td>...</td>\n      <td>-528.753174</td>\n      <td>-590.959412</td>\n      <td>-419.493439</td>\n      <td>-398.758026</td>\n      <td>-410.720764</td>\n      <td>-321.664825</td>\n      <td>-270.623779</td>\n      <td>-431.190338</td>\n      <td>-459.90094</td>\n      <td>249.888367\\n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-689.053894</td>\n      <td>-274.34552</td>\n      <td>-286.308258</td>\n      <td>-366.857391</td>\n      <td>-316.082184</td>\n      <td>-260.256073</td>\n      <td>-98.626152</td>\n      <td>-327.513275</td>\n      <td>-265.838684</td>\n      <td>-436.772949</td>\n      <td>...</td>\n      <td>-405.935669</td>\n      <td>-472.129517</td>\n      <td>-302.524414</td>\n      <td>-278.067261</td>\n      <td>-294.017578</td>\n      <td>-200.974045</td>\n      <td>-151.528046</td>\n      <td>-317.677216</td>\n      <td>-340.805206</td>\n      <td>375.098389\\n</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"exec_count":9}},"exec_count":9,"start":1519249091708,"input":"header = headerdata[0] # en el renglón 21 están los encabezados que corresponden a la localización \n                        # de de los electrodos\n\ndf = pd.DataFrame(headerdata[18:1023], #Toma los renglones que incluiremos en el DataFrame\n                np.arange(0,len(headerdata[18:1023])) #Índice vertical, correspondiente al tiempo\n                  ,header) #Índice horizontal, correspondiente a los electrodos\n\ndf.head()# nos muestra los primeros 5 renglones del DataFrame construido","state":"done","pos":6,"cell_type":"code","type":"cell","end":1519249091779,"id":"c3aa78","kernel":"python3"}
{"output":{"0":{"data":{"text/plain":"(983, 2)"},"exec_count":18}},"exec_count":18,"start":1519249093618,"input":"pca_2comp = PCA(n_components=2) #especificamos el número de componentes principales.\npca_2comp.fit(scaled_data) # ajusta el PCA a nuestro DataFrame reescalado\ndata_2d = pca_2comp.transform(scaled_data) # ajusta el PCA a nuestro DataFrame reescalado\ndata_2d.shape #verificamos la dimensión de nuestros nuevos datos","state":"done","pos":20,"cell_type":"code","type":"cell","end":1519249093670,"id":"d88241","kernel":"python3"}
{"output":{"0":{"data":{"text/plain":"0.9985629044909365"},"exec_count":17}},"exec_count":17,"start":1519249093607,"input":"sum(percent[0:2])","state":"done","pos":18,"cell_type":"code","type":"cell","end":1519249093616,"id":"463d9d","kernel":"python3"}
{"output":{"0":{"data":{"text/plain":"PCA(copy=True, iterated_power='auto', n_components=21, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)"},"exec_count":13}},"exec_count":13,"start":1519249092959,"input":"pca_21comp.fit(scaled_data) # ajusta el PCA a nuestro DataFrame reescalado","state":"done","pos":12,"cell_type":"code","type":"cell","end":1519249093013,"id":"58ac0b","kernel":"python3"}
{"output":{"0":{"data":{"text/plain":"Text(0,0.5,'% de varianza explicada')"},"exec_count":16},"1":{"data":{"image/png":"6f35f45d61698ce5d560c274686a2d81271504c2"}}},"exec_count":16,"start":1519249093058,"input":"plt.figure(figsize=(10,7))\nplt.plot(np.arange(0,21),percent[0:],lw=.7)\nplt.scatter(np.arange(0,21),percent[0:],s=3.5,c='b')\nplt.xlabel(\"Componente Principal\")\nplt.ylabel(\"% de varianza explicada\")","state":"done","pos":16,"cell_type":"code","type":"cell","end":1519249093598,"id":"2aa9f2","kernel":"python3"}
{"output":{"0":{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7f88ce32eb70>,\n <matplotlib.lines.Line2D at 0x7f88ce32ecc0>]"},"exec_count":22},"1":{"data":{"image/png":"6ea9a59393b6fb5b871820a6e23cef771a8bda5c"}}},"exec_count":22,"start":1519250117655,"input":"plt.plot(data_2d)","state":"done","pos":20.5,"type":"cell","end":1519250117907,"id":"e9fb16","kernel":"python3"}
{"output":{"0":{"name":"stderr","text":"/usr/local/lib/python3.5/dist-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: The set_color_cycle attribute was deprecated in version 1.5. Use set_prop_cycle instead.\n  warnings.warn(message, mplDeprecation, stacklevel=1)\n"},"1":{"data":{"image/png":"84ab9f195e30a309216f77da844ffffba1d39d8c"}}},"exec_count":19,"start":1519249093699,"input":"import numpy as np\nimport matplotlib.pyplot as plt\nc = np.arange(1,100)\nx = data_2d[:,0]\ny = data_2d[:,1]\n\ncm = plt.get_cmap('YlOrRd')\n\nfig = plt.figure(figsize=(10,8))\nax1 = plt.subplot(111)\n\nno_points = len((data_2d[:,0]))\nax1.set_color_cycle([cm(1.*i/(no_points-1)) \n                     for i in range(no_points-1)])\n\n\nfor i in range(no_points-1):\n    ax1.plot(x[i:i+2],y[i:i+2],lw=.5)\n\nax1.scatter(data_2d[:,0],data_2d[:,1],marker='.',s=6,c='black')\nplt.xlabel('Primer componente principal')\nplt.ylabel('Segunda componente principal')\n    \nplt.show()","state":"done","pos":22,"cell_type":"code","type":"cell","end":1519249096680,"id":"226e6b","kernel":"python3"}
{"output":{"0":{"name":"stderr","text":"/usr/local/lib/python3.5/dist-packages/matplotlib/contour.py:967: UserWarning: The following kwargs were not used by contour: 'kde'\n  s)\n"},"1":{"data":{"text/plain":"<function matplotlib.pyplot.tight_layout>"},"exec_count":20},"2":{"data":{"text/plain":"<matplotlib.figure.Figure at 0x7f88ce22bcc0>"}},"3":{"data":{"image/png":"cf0da240b4fe1b256fd5170ccf067752703fb9dc"}}},"exec_count":20,"start":1519249096693,"input":"plt.figure(figsize=(10,8))\nsns.jointplot(data_2d[:,0],data_2d[:,1],kind='kde',kde=False,cmap='OrRd')\n#plt.scatter(data_2d[:,0],data_2d[:,1],s=.2,c='r')\nplt.xlabel('Primer componente principal')\nplt.ylabel('Segunda componente principal')\nplt.tight_layout","state":"done","pos":23,"cell_type":"code","type":"cell","end":1519249099233,"id":"3f4944","kernel":"python3"}
{"type":"cell","id":"11c620","pos":0,"input":"<a id='introduction'></a>\n## 1. Introducción - Series de tiempo multivariadas\nUna forma muy efectiva de estudiar series de tiempo es extraer caracerísticas generales y/o patrones en los datos que nos permitan interpretar, clasificar o predecir el comportamiento de dicha serie. Sin embargo, este tipo de análisis puede volverse muy complicado cuando las series de tiempo son $multivariadas$, es decir, que toman en cuenta los cambios en el tiempo de más de una variable$^1$. Un ejemplo sencillo de una serie de tiempo multivariada sería medir el ritmo cardiaco, la actividad muscular y la temperatura corporal de un corredor a lo largo del tiempo, otro ejemplo lo podemos encontrar en los electroencefalogramas (EEG), los cuales registran actividad cerebral en 21, 64 o 256 canales (dependiendo del equipo de registro utilizado), por lo que encontrar patrones en este tipo de series de tiempo mediante métodos estadísticos tradicionales puede resultar complicado.\n","cell_type":"markdown"}
{"type":"cell","id":"241340","pos":1,"input":"Como es costumbre, primero importaremos las librerías:","cell_type":"markdown"}
{"type":"cell","id":"28511e","pos":17,"input":"Es possible ver que la primer componente logra capturar alrededor del 97% de la varianza y con las primeras dos componentes principales capturamos .998 de la varianza total. Ahora vamos a reducir la dimensión de los datos a dos dimensiones:","cell_type":"markdown"}
{"type":"cell","id":"5231e1","pos":20.25,"input":"A continuación graficaremos los datos del EEG original en términos de las primeras dos componentes principales:","cell_type":"markdown"}
{"type":"cell","id":"59df84","pos":-1,"input":"# Introducción al análisis de series de tiempo con PCA\n### Noel Isaías Placencia-Díaz, Erin C. McKiernan, Marco Arieli Herrera-Valdez,\n### Facultad de Ciencias, UNAM\n","cell_type":"markdown"}
{"type":"cell","id":"7c4ea2","pos":14,"input":"<a id='scree'></a>\n#### 4.1 Scree Diagram\nUna forma de decidir qué tanto vamos a reducir la dimensión de nuestros datos es usando un $scree$ $diagram$, que simplemente es una gráfica de los eigenvalores correspondientes a cada una de las componentes principales","cell_type":"markdown"}
{"type":"cell","id":"812841","pos":-0.5,"input":"## Tabla de contenidos:\n\n[1. Introducción](#introduction)\n\n[1.1 Introducción a PCA](#intro_pca)\n\n[2. Importar EEG](#import_eeg)\n\n[2.1 Colocar los datos de una serie de tiempo multivariada en un dataframe](#eeg_df)\n\n[3. Preprocesamiento - ormalizar la varianza ](#norm_var)\n\n[4. Aplicar PCA ](#apply_pca)\n\n[4.1 Scree Diagram ](#scree)\n\n[4.2 Aplicar PCA reduciendo la dimensión de los datos](#dim_red)\n\n[4.3 Análisis en el espacio de las componentes pricipales](#pca_space)","cell_type":"markdown"}
{"type":"cell","id":"9c958a","pos":10,"input":"<a id='apply_pca'></a>\n#### 4. Aplicación de PCA\nPara aplicar PCA con scikit debemos de proceder de forma análoga a cuando aplicamos el escalamiento anterior:","cell_type":"markdown"}
{"type":"cell","id":"9d331a","pos":7,"input":"<a id='norm_var'></a>\n#### 3. Preprocesamiento - Normalizar la varianza\nPara realizar PCA es conveniente que los datos tengan una varianza normalizada, scikit-learn tiene una herramienta que hará esto de manera automatica:","cell_type":"markdown"}
{"type":"cell","id":"a99f76","pos":5,"input":"<a id='eeg_df'></a>\n#### 2.1 Preparamos un DataFrame\nPara series de tiempo multidimensionales, resulta útil tener un DataFrame  de nuestros datos, haremos esto con Pandas en el registro de EEG, en donde por columnas tendremos a cada una de las señales correspondientes a los electrodos y cada renglón corresponde a una \"medición\" del electroencefalograma:","cell_type":"markdown"}
{"type":"cell","id":"ab695b","pos":19,"input":"<a id='dim_red'></a>\n#### 4.2 Aplicar PCA a los datos reduciendo la dimensión","cell_type":"markdown"}
{"type":"cell","id":"ac5eca","pos":3,"input":"<a id='import_eeg'></a>\n#### 2. Importamos los datos del EEG:","cell_type":"markdown"}
{"type":"cell","id":"cf644f","pos":0.5,"input":"<a id='intro_pca'></a>\n## 1.1 Introducción a Pincipal Component Analysis (PCA)\nPrincipal Component Analysis (PCA) es una herramienta que permite encontrar patrones o características descripitivas en conjuntos de datos multidimensonales y series de tiempo multivaluadas mediante un proceso que resalta características de similitud y diferencia en los datos, además una de las principales ventajas de utilizar PCA es que permite reducir la dimensionalidad de los datos.\n\nEl algoritmo de PCA se basa en encontrar cuáles son las direcciones de mayor varianza en el conjunto de datos, estas son llamadas $componentes$ $principales$. Para esto, se siguen los siguientes pasos:\n\n    1) Obtener una matríz de covarianza de los datos.\n\n    2) Extraer los eigenvectores y eigenvalores de la matríz de covarianza.\n\n    3) Dimensión de reduccion: este paso consiste en elegir los eigenvectores cuyos eigenvalores correspondientes son los mayores y crear una nueva matríz sólo con los eigenvectores elegidos, a estos se les llama componentes principales.\n\n    4) Proyectar la matríz de componentes principales sobre los datos originales.\n\nPara aplicar PCA a un conjunto de datos multidimensional utilizaremos datos de un EEG de 21 canales y la paquetería $\\textit{scikit-learn}^2$, sin embargo, si quieres aprender un poco más acerca de los detalles matemáticos detrás de PCA, $\\textbf{lo cual es muy recomendable}$, puedes hacerlo en el siguiente tutorial: https://klevas.mif.vu.lt/~tomukas/Knygos/principal_components.pdf\n\n##### Notas:\n$^1$ Hasta  el momento sólo habíamos estudiado series de tiempo univariadas (como cambios del voltaje en el tiempo)\n\n$^2$ http://scikit-learn.org/stable/","cell_type":"markdown"}
{"type":"cell","id":"f617e8","pos":21,"input":"<a id='pca_space'></a>\n#### 4.2 Aplicar PCA a los datos reduciendo la dimensión\nUna forma de analizar los datos transformados con PCA es mediante un método llamado reconstrucción del espacio fase, cuyo objetivo es analizar las trayectorias del sistema dinámico subyacente a una serie de tiempo construyendo un conjunto $\\textit{vectores de estado}$ dados por los datos que corresopnden a las variables de nuestro sistema. Es común que después de reconstruir el espacio fase, se analice la existencia de atractores y se utilicen herramientas para caracterizar a estos mismos. La siguiente gráfica es un ejemplo de la reconstrucción del espacio fase de nuestros datos en términos de las componentes principales, donde la intensidad del color de la línea corresponde a la secuencia temporal de los datos.","cell_type":"markdown"}
{"type":"file","last_load":1518578587372}
{"type":"settings","kernel":"python3","backend_state":"running","metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"trust":true,"kernel_usage":{"cpu":0,"memory":88170496},"kernel_state":"idle"}